{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ad15b4-e9e5-4b38-97ba-40ad8a9da892",
   "metadata": {},
   "source": [
    "# Data cleansing and extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb960e46-526a-4f98-961f-617c690f0892",
   "metadata": {},
   "source": [
    "The dataset we will be using during this project can be found both on [Kaggle](https://www.kaggle.com/datasets/uciml/forest-cover-type-dataset?resource=download) and University of California, Irvine's ML [Repository](https://archive.ics.uci.edu/dataset/31/covertype) (where, in addition to the data, you can find a more extended explanaition on the variable meaning that the Kaggle page lacks).\n",
    "\n",
    "Let's begin by extracting the data and loading it to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159bc2a8-4924-459e-8af1-dba8ec6c4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07cf733f-81e6-467f-bb76-f7c9b5805799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column                              Non-Null Count   Dtype\n",
      "---  ------                              --------------   -----\n",
      " 0   Elevation                           581012 non-null  int64\n",
      " 1   Aspect                              581012 non-null  int64\n",
      " 2   Slope                               581012 non-null  int64\n",
      " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
      " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
      " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
      " 6   Hillshade_9am                       581012 non-null  int64\n",
      " 7   Hillshade_Noon                      581012 non-null  int64\n",
      " 8   Hillshade_3pm                       581012 non-null  int64\n",
      " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
      " 10  Wilderness_Area1                    581012 non-null  int64\n",
      " 11  Wilderness_Area2                    581012 non-null  int64\n",
      " 12  Wilderness_Area3                    581012 non-null  int64\n",
      " 13  Wilderness_Area4                    581012 non-null  int64\n",
      " 14  Soil_Type1                          581012 non-null  int64\n",
      " 15  Soil_Type2                          581012 non-null  int64\n",
      " 16  Soil_Type3                          581012 non-null  int64\n",
      " 17  Soil_Type4                          581012 non-null  int64\n",
      " 18  Soil_Type5                          581012 non-null  int64\n",
      " 19  Soil_Type6                          581012 non-null  int64\n",
      " 20  Soil_Type7                          581012 non-null  int64\n",
      " 21  Soil_Type8                          581012 non-null  int64\n",
      " 22  Soil_Type9                          581012 non-null  int64\n",
      " 23  Soil_Type10                         581012 non-null  int64\n",
      " 24  Soil_Type11                         581012 non-null  int64\n",
      " 25  Soil_Type12                         581012 non-null  int64\n",
      " 26  Soil_Type13                         581012 non-null  int64\n",
      " 27  Soil_Type14                         581012 non-null  int64\n",
      " 28  Soil_Type15                         581012 non-null  int64\n",
      " 29  Soil_Type16                         581012 non-null  int64\n",
      " 30  Soil_Type17                         581012 non-null  int64\n",
      " 31  Soil_Type18                         581012 non-null  int64\n",
      " 32  Soil_Type19                         581012 non-null  int64\n",
      " 33  Soil_Type20                         581012 non-null  int64\n",
      " 34  Soil_Type21                         581012 non-null  int64\n",
      " 35  Soil_Type22                         581012 non-null  int64\n",
      " 36  Soil_Type23                         581012 non-null  int64\n",
      " 37  Soil_Type24                         581012 non-null  int64\n",
      " 38  Soil_Type25                         581012 non-null  int64\n",
      " 39  Soil_Type26                         581012 non-null  int64\n",
      " 40  Soil_Type27                         581012 non-null  int64\n",
      " 41  Soil_Type28                         581012 non-null  int64\n",
      " 42  Soil_Type29                         581012 non-null  int64\n",
      " 43  Soil_Type30                         581012 non-null  int64\n",
      " 44  Soil_Type31                         581012 non-null  int64\n",
      " 45  Soil_Type32                         581012 non-null  int64\n",
      " 46  Soil_Type33                         581012 non-null  int64\n",
      " 47  Soil_Type34                         581012 non-null  int64\n",
      " 48  Soil_Type35                         581012 non-null  int64\n",
      " 49  Soil_Type36                         581012 non-null  int64\n",
      " 50  Soil_Type37                         581012 non-null  int64\n",
      " 51  Soil_Type38                         581012 non-null  int64\n",
      " 52  Soil_Type39                         581012 non-null  int64\n",
      " 53  Soil_Type40                         581012 non-null  int64\n",
      " 54  Cover_Type                          581012 non-null  int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 243.8 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/covtype.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5adba79-e52d-41fc-bf6f-2167da4c1dca",
   "metadata": {},
   "source": [
    "The dataset is pretty heavy. On a first sight, we can see that:\n",
    "- There are more than half a million entries and more than 50 columns!\n",
    "- All variables are numeric. But many variables are produced following the **One-hot encoder** approach for converting categorical variables into numeric variables.\n",
    "- **cover_type** is the target variable we want to predict. With such a big set of information, we can apply many different classical Machine Learning (and maybe some basic neural network) models to try to predict the possible cover_type of a pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e434f91b-f1cc-40dd-936d-e6d6c99a6c5b",
   "metadata": {},
   "source": [
    "## Open questions: to be answered in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926120b6-3d63-4b9d-824f-88aca5f5bff8",
   "metadata": {},
   "source": [
    "1. Are different soil types compatible? I mean: is it possible for a pixel to have more than one soil type, and thus have more than one True value in the soil columns?\n",
    "2. Are all soil types equally represented? Is there a soil type with mostly `False` values? If the latter is true, we could drop that column.\n",
    "3. Can we group the different soil types into a smaller number of columns? Maybe different soil types show themselves in groups. In that case, we could just create a new column per group and drop the individual columns.\n",
    "4. From the ML point of view: which are the most influential columns? How much can we simplify the dataset by dropping columns?\n",
    "5. Is it possible to reduce the amount of columns by combining them in a single column? Not by creating columns that represent soil type groups, but by merging all of them (or as many of them as possible) in a single column, where each soil type would be represented by an index value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f5c12-aa19-4e35-8138-f38f1bd413b3",
   "metadata": {},
   "source": [
    "## Future steps:\n",
    "(provisional, this cell will be moved to a different notebook or file in the future)\n",
    "\n",
    "- Is this compatible with other forests? Is it compatible with other forest types?\n",
    "- Can it be combined with satellite data?\n",
    "- Is it possible to create a pipeline where satellite data would be preprocessed with ML algorithms (CV?) to get scalar values that represent each soil type and then combine it to the model developed in this project to guess cover type? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421040ab-3841-4bc4-90d1-0a5dcef84a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
